{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f3c2bb4",
   "metadata": {},
   "source": [
    "# Build Model Weather-Related Disease Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3171385",
   "metadata": {},
   "source": [
    "On this process we will build the model to predict based on the target variable (prognosis). We also want to find out which model is the best."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0c46e9",
   "metadata": {},
   "source": [
    "## Setup & Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc7097f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "454baba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548ad09e",
   "metadata": {},
   "source": [
    "## Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d298b999",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Temperature (C)</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Wind Speed (km/h)</th>\n",
       "      <th>nausea</th>\n",
       "      <th>joint_pain</th>\n",
       "      <th>abdominal_pain</th>\n",
       "      <th>high_fever</th>\n",
       "      <th>chills</th>\n",
       "      <th>...</th>\n",
       "      <th>facial_pain</th>\n",
       "      <th>shortness_of_breath</th>\n",
       "      <th>reduced_smell_and_taste</th>\n",
       "      <th>skin_irritation</th>\n",
       "      <th>itchiness</th>\n",
       "      <th>throbbing_headache</th>\n",
       "      <th>confusion</th>\n",
       "      <th>back_pain</th>\n",
       "      <th>knee_ache</th>\n",
       "      <th>prognosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>25.826</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>8.289000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Heart Attack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>21.628</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>15.236000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Influenza</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>13.800</td>\n",
       "      <td>0.817083</td>\n",
       "      <td>4.291992</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Influenza</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>37.254</td>\n",
       "      <td>0.610000</td>\n",
       "      <td>18.009000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Dengue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>18.162</td>\n",
       "      <td>0.870000</td>\n",
       "      <td>17.916000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Sinusitis</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Gender  Temperature (C)  Humidity  Wind Speed (km/h)  nausea  \\\n",
       "0    4       1           25.826  0.740000           8.289000       1   \n",
       "1   55       0           21.628  0.600000          15.236000       0   \n",
       "2   45       0           13.800  0.817083           4.291992       0   \n",
       "3    6       0           37.254  0.610000          18.009000       1   \n",
       "4   70       0           18.162  0.870000          17.916000       0   \n",
       "\n",
       "   joint_pain  abdominal_pain  high_fever  chills  ...  facial_pain  \\\n",
       "0           0               0           0       0  ...            0   \n",
       "1           0               0           0       1  ...            0   \n",
       "2           0               0           0       0  ...            0   \n",
       "3           0               0           1       0  ...            0   \n",
       "4           0               0           0       0  ...            1   \n",
       "\n",
       "   shortness_of_breath  reduced_smell_and_taste  skin_irritation  itchiness  \\\n",
       "0                    1                        0                0          0   \n",
       "1                    0                        0                0          0   \n",
       "2                    0                        0                0          0   \n",
       "3                    0                        0                0          0   \n",
       "4                    0                        0                0          0   \n",
       "\n",
       "   throbbing_headache  confusion  back_pain  knee_ache     prognosis  \n",
       "0                   0          0          0          0  Heart Attack  \n",
       "1                   0          0          0          0     Influenza  \n",
       "2                   0          0          0          0     Influenza  \n",
       "3                   0          0          0          0        Dengue  \n",
       "4                   0          0          0          0     Sinusitis  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "path = path = \"D:\\\\Project Data Analysis\\\\Data & src code\\\\Weather Related Disease Prediction\\\\data\\\\raw\\\\Weather-related disease prediction.csv\"\n",
    "df = pd.read_csv(path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4431162",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772dc398",
   "metadata": {},
   "source": [
    "### Label Encoding for Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "131c81c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the target variable\n",
    "le = LabelEncoder()\n",
    "df['prognosis'] = le.fit_transform(df['prognosis']) # Encoding the target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3056ee35",
   "metadata": {},
   "source": [
    "For the first setp we're  gonna encode all the category into number so is gonna make the model easy to run the target for prediction. In this case we use label encoder and transfrom to the prognosis feature. For other feature like Age, Temperature, Humidity, and Wind Speed we don't need to encode because we consider to make the model stick to the original data so that the model can predict well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7010e4",
   "metadata": {},
   "source": [
    "### Define Train-Test Data and Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8a2807f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define train-test data and target variable\n",
    "X = df.drop(columns=['prognosis']) # training data\n",
    "y = df['prognosis'] # target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897712b7",
   "metadata": {},
   "source": [
    "Next, we gonna define the train-test data and target variable. In this data we decide to make prognosis feature as target variable, so the X is going to be data without target and y is a target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73fad07d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4     1013\n",
       "8      941\n",
       "6      658\n",
       "5      338\n",
       "7      330\n",
       "10     329\n",
       "3      327\n",
       "2      322\n",
       "1      321\n",
       "0      311\n",
       "9      310\n",
       "Name: prognosis, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking y value counts\n",
    "y.value_counts() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8d41bb",
   "metadata": {},
   "source": [
    "### Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9131375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets 80:20\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2db96a8",
   "metadata": {},
   "source": [
    "After we define the X and y, we split the data into train and test with scale 80:20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49bf5e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of data train: 4160 row, 50 column\n",
      "Size of data test: 1040 row, 50 column\n"
     ]
    }
   ],
   "source": [
    "# checking the shape of the data\n",
    "print(f\"Size of data train: {X_train.shape[0]} row, {X_train.shape[1]} column\")\n",
    "print(f\"Size of data test: {X_test.shape[0]} row, {X_test.shape[1]} column\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c31a3efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y train: 4     821\n",
      "8     740\n",
      "6     522\n",
      "7     269\n",
      "5     267\n",
      "2     264\n",
      "1     262\n",
      "3     259\n",
      "9     253\n",
      "0     253\n",
      "10    250\n",
      "Name: prognosis, dtype: int64\n",
      "y test: 8     201\n",
      "4     192\n",
      "6     136\n",
      "10     79\n",
      "5      71\n",
      "3      68\n",
      "7      61\n",
      "1      59\n",
      "0      58\n",
      "2      58\n",
      "9      57\n",
      "Name: prognosis, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# checking y values\n",
    "print(f\"y train: {y_train.value_counts()}\")\n",
    "print(f\"y test: {y_test.value_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27828f3",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ecdf6a0",
   "metadata": {},
   "source": [
    "When the data is ready, we are going to build the model and find the best parameter with hypertuning. On this process we use two different models, the first one is Random Forest, we choose Random Forest because this model is match for data tabualar. The second model is XGBoost, we use this model because this model is more flexible for the data that has imbalance data, and good on overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986dfab6",
   "metadata": {},
   "source": [
    "#### Random Forest Model Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "543b95d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Random Forest Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        58\n",
      "           1       0.91      0.98      0.94        59\n",
      "           2       0.98      0.98      0.98        58\n",
      "           3       1.00      1.00      1.00        68\n",
      "           4       1.00      0.99      1.00       192\n",
      "           5       0.97      1.00      0.99        71\n",
      "           6       0.99      0.96      0.97       136\n",
      "           7       1.00      0.98      0.99        61\n",
      "           8       0.98      1.00      0.99       201\n",
      "           9       1.00      1.00      1.00        57\n",
      "          10       0.99      0.95      0.97        79\n",
      "\n",
      "    accuracy                           0.99      1040\n",
      "   macro avg       0.98      0.99      0.98      1040\n",
      "weighted avg       0.99      0.99      0.99      1040\n",
      "\n",
      "\n",
      "Accuracy Score: 0.9855769230769231\n"
     ]
    }
   ],
   "source": [
    "# initializing the random forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train) # fit the model on the training data\n",
    "y_pred = rf_model.predict(X_test) # make predictions on the test data\n",
    "\n",
    "# checking with classification report\n",
    "print(\"\\n Random Forest Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"\\nAccuracy Score:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7bed866",
   "metadata": {},
   "source": [
    "After we try to fit the data into the Random Forest model, as we can see the data run it well with 98% accuracy, even if we see on the class variance they have a good balance between precision and recall."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40613b28",
   "metadata": {},
   "source": [
    "### Hypertuning for Random Forest Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eccaa45",
   "metadata": {},
   "source": [
    "On this process, we will look what best parameter to Random Forest using grid_search and we also using Cross Validation to avoid overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83db7572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 216 candidates, totalling 648 fits\n",
      "Best Parameters: {'max_depth': 30, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 200}\n",
      "Best Cross-Validation Accuracy: 0.98124999783255\n",
      "\n",
      " Random Forest Classification Report after Hyperparameter Tuning:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        58\n",
      "           1       0.89      0.98      0.94        59\n",
      "           2       0.98      0.98      0.98        58\n",
      "           3       1.00      1.00      1.00        68\n",
      "           4       1.00      0.99      0.99       192\n",
      "           5       0.97      1.00      0.99        71\n",
      "           6       0.99      0.95      0.97       136\n",
      "           7       1.00      0.98      0.99        61\n",
      "           8       0.98      1.00      0.99       201\n",
      "           9       1.00      1.00      1.00        57\n",
      "          10       0.99      0.95      0.97        79\n",
      "\n",
      "    accuracy                           0.98      1040\n",
      "   macro avg       0.98      0.98      0.98      1040\n",
      "weighted avg       0.98      0.98      0.98      1040\n",
      "\n",
      "\n",
      "Accuracy Score after Hyperparameter Tuning: 0.9836538461538461\n"
     ]
    }
   ],
   "source": [
    "# make a parameter grid for hyperparameter tuning for Random Forest\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['auto', 'sqrt'],\n",
    "}\n",
    "\n",
    "# Perform grid search for hyperparameter tuning\n",
    "grid_search_rf = GridSearchCV(estimator=rf_model, param_grid=rf_param_grid, cv=3, n_jobs=-1, verbose=2)\n",
    "grid_search_rf.fit(X_train, y_train) # fit the model on the training data\n",
    "\n",
    "# showing the best parameters and score\n",
    "print(\"Best Parameters:\", grid_search_rf.best_params_)\n",
    "print(\"Best Cross-Validation Accuracy:\", grid_search_rf.best_score_)\n",
    "\n",
    "# use the best estimator to make predictions\n",
    "best_rf_model = grid_search_rf.best_estimator_\n",
    "y_pred_best_rf = best_rf_model.predict(X_test) # make predictions on the test data\n",
    "\n",
    "# checking with classification report\n",
    "print(\"\\n Random Forest Classification Report after Hyperparameter Tuning:\")\n",
    "print(classification_report(y_test, y_pred_best_rf))\n",
    "print(\"\\nAccuracy Score after Hyperparameter Tuning:\", accuracy_score(y_test, y_pred_best_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8441d95c",
   "metadata": {},
   "source": [
    "After fitting the model in 3 fold using cross validation the result after overfitting don't have significance difference, the model before tuning is slightly better but overall both model give a good accuracy. Besides, the cross validation also give the good result with 98% accuracy and we can also see the best parameter we can use:\n",
    "\n",
    "* max_depth: 30, \n",
    "* max_features :  sqrt \n",
    "* min_samples_leaf: 1 \n",
    "* min_samples_split: 10\n",
    "* n_estimators: 200\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c3125c",
   "metadata": {},
   "source": [
    "### XGBoost Model Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8b9721f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " XGBoost Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        58\n",
      "           1       0.92      0.97      0.94        59\n",
      "           2       0.98      0.98      0.98        58\n",
      "           3       1.00      1.00      1.00        68\n",
      "           4       1.00      0.99      0.99       192\n",
      "           5       0.97      0.99      0.98        71\n",
      "           6       0.99      0.96      0.98       136\n",
      "           7       1.00      0.98      0.99        61\n",
      "           8       0.97      1.00      0.98       201\n",
      "           9       1.00      1.00      1.00        57\n",
      "          10       0.99      0.95      0.97        79\n",
      "\n",
      "    accuracy                           0.98      1040\n",
      "   macro avg       0.98      0.98      0.98      1040\n",
      "weighted avg       0.98      0.98      0.98      1040\n",
      "\n",
      "\n",
      "Accuracy Score: 0.9836538461538461\n"
     ]
    }
   ],
   "source": [
    "xgb_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
    "xgb_model.fit(X_train, y_train) # fit the model on the training data\n",
    "y_pred_xgb = xgb_model.predict(X_test) # make predictions on the test data\n",
    "\n",
    "# checking with classification report\n",
    "print(\"\\n XGBoost Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_xgb))\n",
    "print(\"\\nAccuracy Score:\", accuracy_score(y_test, y_pred_xgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789b6650",
   "metadata": {},
   "source": [
    "If we try to fit the data to the XGBoost model, the accuracy score that we have is 98.3%, just a little bit smaller than Random Forest but it's not a big difference, the model still have good model to predict the class, the precision and recall also have a good score on each class same as Random Forest."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fc2332",
   "metadata": {},
   "source": [
    "### Hypertuning for XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "72c28e66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 243 candidates, totalling 729 fits\n",
      "Best Parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.2, 'max_depth': 5, 'n_estimators': 100, 'subsample': 1.0}\n",
      "Best Cross-Validation Accuracy: 0.978605362167006\n",
      "\n",
      " XGBoost Classification Report after Hyperparameter Tuning:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        58\n",
      "           1       0.91      0.98      0.94        59\n",
      "           2       0.98      0.98      0.98        58\n",
      "           3       1.00      1.00      1.00        68\n",
      "           4       1.00      0.99      0.99       192\n",
      "           5       0.97      1.00      0.99        71\n",
      "           6       0.98      0.96      0.97       136\n",
      "           7       1.00      0.98      0.99        61\n",
      "           8       0.98      1.00      0.99       201\n",
      "           9       1.00      1.00      1.00        57\n",
      "          10       0.99      0.95      0.97        79\n",
      "\n",
      "    accuracy                           0.98      1040\n",
      "   macro avg       0.98      0.99      0.98      1040\n",
      "weighted avg       0.99      0.98      0.98      1040\n",
      "\n",
      "\n",
      "Accuracy Score after Hyperparameter Tuning: 0.9846153846153847\n"
     ]
    }
   ],
   "source": [
    "# make a parameter grid for hyperparameter tuning for XGBoost\n",
    "xgb_param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'subsample': [0.5, 0.7, 1.0],\n",
    "    'colsample_bytree': [0.5, 0.7, 1.0],\n",
    "}\n",
    "\n",
    "# Perform grid search for hyperparameter tuning\n",
    "grid_search_xgb = GridSearchCV(estimator=xgb_model, param_grid=xgb_param_grid, cv=3, n_jobs=-1, verbose=2)\n",
    "grid_search_xgb.fit(X_train, y_train) # fit the model on the training data\n",
    "\n",
    "# showing the best parameters and score\n",
    "print(\"Best Parameters:\", grid_search_xgb.best_params_)\n",
    "print(\"Best Cross-Validation Accuracy:\", grid_search_xgb.best_score_)\n",
    "\n",
    "# use the best estimator to make predictions\n",
    "best_xgb_model = grid_search_xgb.best_estimator_\n",
    "y_pred_best_xgb = best_xgb_model.predict(X_test) # make predictions on the test data\n",
    "\n",
    "# checking with classification report\n",
    "print(\"\\n XGBoost Classification Report after Hyperparameter Tuning:\")\n",
    "print(classification_report(y_test, y_pred_best_xgb))\n",
    "print(\"\\nAccuracy Score after Hyperparameter Tuning:\", accuracy_score(y_test, y_pred_best_xgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff81bd7f",
   "metadata": {},
   "source": [
    "After we use the hypertuning to XGBoost model and use the cross validation, the accuracy have slightly better before hypertuning. The cross validation is also show that the accuracy is 97% which mean the model is already good and have optimal performance when trying to predict the class. For the best parameter to use XGBoost model:\n",
    "\n",
    "* colsample_bytree: 0.5 \n",
    "* learning_rate: 0.2 \n",
    "* max_depth: 5\n",
    "* n_estimators: 100 \n",
    "* subsample: 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea3bf10",
   "metadata": {},
   "source": [
    "The next process is evaluation. In the evaluation we will evaluate the model and compare the prediction on each class using the confusion matrix and feature/permutation importance to see which feature has the high influence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ef787e",
   "metadata": {},
   "source": [
    "## Save Model & Data Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f55bb4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fa7faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[âœ“] Model Random Forest dan test data berhasil disimpan.\n"
     ]
    }
   ],
   "source": [
    "# Save model & data test\n",
    "os.makedirs('models', exist_ok=True)\n",
    "joblib.dump(rf_model, 'models/rf_model.pkl') # using the default model\n",
    "joblib.dump(X_test, 'models/X_test.pkl')\n",
    "joblib.dump(y_test, 'models/y_test.pkl')\n",
    "\n",
    "print(\"[âœ“] Model Random Forest dan test data berhasil disimpan.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babbb7c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[âœ“] Model XGBoost berhasil disimpan.\n"
     ]
    }
   ],
   "source": [
    "joblib.dump(best_xgb_model, '../models/xgb_model.pkl') # using the best model\n",
    "print(\"[âœ“] Model XGBoost berhasil disimpan.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
